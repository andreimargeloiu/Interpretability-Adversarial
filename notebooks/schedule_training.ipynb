{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of train_ham10000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('robustness': conda)",
      "language": "python",
      "name": "python37764bitrobustnessconda89407f630c9b4a1790a22e1cca783b6d"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KJ-bpTO71J6J",
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Schedule training\n",
        "\n",
        "This script installs the dependencies in Colab, and schedules training of many notebooks. This notebook calls the training scripr \"training.ipynb\".\n",
        "\n",
        "How to run:\n",
        "\n",
        "1. Find the lines \"TODO-USER\" in this notebook to complete basic settings (e.g., set logging paths)\n",
        "2. Find the lines \"TODO-USER\" in the notebook \"training.ipynb\" to set the paths\n",
        "3. Simply run the script :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0JTdgJo1J6K",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ydUiekl51J6L",
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gAaOmTFd1tzK",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C3zr2AI41J6a",
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "# @title Install Project\n",
        "%cd /content\n",
        "!git clone https://github.com/margiki/Interpretability-Adversarial.git\n",
        "%cd /content/Interpretability-Adversarial\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "source": [
        "# TODO-USER change these settings "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO-USER change these when running the notebook\n",
        "# The data set is downloaded from kaggle.com. You need to create a free kaggle account to download the data, and then paste the username and key in here.\n",
        "KAGGLE_USERNAME = None\n",
        "KAGGLE_KEY = None\n",
        "# Path for downloaded reproducibility material (e.g., data splits)\n",
        "REPRODUCIBILITY_PATH = None (e.g., '/content/drive/My\\ Drive/reproducibility')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_SPLIT_PATH = f\"{REPRODUCIBILITY_PATH}/dataset_splits/*\"\n",
        "USER_MODELS_PATH = f\"{REPRODUCIBILITY_PATH}/models\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KX3mGOOGzMoL",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":f\"{KAGGLE_USERNAME}\",\"key\":f\"{KAGGLE_KEY}\"}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cBndm4yKzQju",
        "colab": {}
      },
      "source": [
        "!mkdir /content/data\n",
        "!kaggle datasets download kmader/skin-cancer-mnist-ham10000 -p /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jda3RFGhzSP3",
        "colab": {}
      },
      "source": [
        "# Unzip the whole zipfile into /content/data\n",
        "!unzip -o /content/data/skin-cancer-mnist-ham10000.zip -d /content/data\n",
        "\n",
        "!rm -rf /content/data/HAM10000_images_part_1\n",
        "!rm -rf /content/data/HAM10000_images_part_2\n",
        "\n",
        "%cd /content/data/ham10000_images_part_1/\n",
        "!ls -1 | wc -l\n",
        "%cd /content/data/ham10000_images_part_2/\n",
        "!ls -1 | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the dataset splits\n",
        "!gsutil -m cp -R $DATA_SPLIT_PATH /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OLQUt6JF1J6r",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "%cd /content/Interpretability-Adversarial\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qi6cf5v71J7O"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2msNc36m1J7P",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import papermill as pm\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from robustness.evaluation import plot_curves_from_file, plot_curves_from_log\n",
        "from robustness import train, defaults, model_utils\n",
        "from cox.utils import Parameters\n",
        "from robustness.datasets import CIFAR, HAM10000_3cls, HAM10000_dataset_3cls_balanced\n",
        "from robustness.tools.utils import fix_random_seed\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YcgX6KEU1J7K"
      },
      "source": [
        "## Training config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEPJ7sXzMaLq",
        "colab": {}
      },
      "source": [
        "OUT_DIR = TODO-USER change this (e.g., \"/content/drive/My Drive/notebooks_runs\")\n",
        "LOG_DIR = TODO-USER change this (e.g., \"/content/drive/My Drive/logs\")\n",
        "DATA_DIR = TODO-USER change this (e.g., \"/Users/andrei/Google Drive/data/HAM10000\")\n",
        "\n",
        "dataset_size = 2400\n",
        "train_file_name = f'3cls_balanced_{dataset_size}_train_val.csv'\n",
        "test_file_name = '3cls_balanced_test_without_val.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-aatUxvjtfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_validation_train(time_expid, val_fold, base_model_expid,\n",
        "                           lr, train_file_name, test_file_name,\n",
        "                           unfreeze_to_layer=-1,\n",
        "                           BATCH_SIZE=16, step_lr=15, EPOCHS=25,\n",
        "                           use_dropout_head=False, dropout_perc=0,\n",
        "                           lr_patience=5, es_patience=10, custom_schedule='plateau', \n",
        "                           ADV_TRAIN=False, EPS=0, constraint='2', arch=\"resnet18\",\n",
        "                           apply_ablation=False, perc_ablation=0, \n",
        "                           do_eval_model=False, TRAIN_COLAB=True,\n",
        "                           expid=None, seed=42):\n",
        "  \"\"\"\n",
        "  Function to run the training for the cross_validation\n",
        "  \"\"\"\n",
        "  saliency_dir = os.path.join(DATA_DIR, 'saliency_maps')\n",
        "  if ADV_TRAIN:\n",
        "    saliency_dir = os.path.join(saliency_dir, 'standard')\n",
        "  else:\n",
        "    saliency_dir = os.path.join(saliency_dir, f'adv {int(EPS)}')\n",
        "\n",
        "  if expid == None:\n",
        "    if params['ADV_TRAIN'] == False:\n",
        "        params['expid'] = f\"cv={val_fold}_full_std_lr={lr}_{dataset_size}_{time_expid}\"\n",
        "    else:\n",
        "        params['expid'] = f\"cv={val_fold}_full_adv_eps={EPS}_lr={lr}_{dataset_size}_{time_expid}\"\n",
        "\n",
        "  params = dict(\n",
        "      TRAIN_COLAB = TRAIN_COLAB,\n",
        "      ADV_TRAIN = ADV_TRAIN,\n",
        "      lr = lr,\n",
        "      BATCH_SIZE = BATCH_SIZE,\n",
        "      EPOCHS = EPOCHS,\n",
        "      base_model_expid = base_model_expid,\n",
        "      unfreeze_to_layer = unfreeze_to_layer,\n",
        "      arch = arch,\n",
        "      step_lr = step_lr,\n",
        "      custom_schedule = custom_schedule,\n",
        "      train_file_name = f\"{train_file_name}::{val_fold}\",\n",
        "      test_file_name = test_file_name,\n",
        "      EPS = EPS,\n",
        "      constraint = '2',\n",
        "      apply_ablation = apply_ablation,\n",
        "      saliency_dir = saliency_dir,\n",
        "      perc_ablation=perc_ablation,\n",
        "      do_eval_model=do_eval_model,\n",
        "      lr_patience=lr_patience,\n",
        "      es_patience=es_patience,\n",
        "      eval_checkpoint_type='best',\n",
        "      use_dropout_head = use_dropout_head,\n",
        "      dropout_perc = dropout_perc,\n",
        "      expid = expid,\n",
        "      seed=seed\n",
        "  )\n",
        "\n",
        "  print(params['expid'])\n",
        "\n",
        "  pm.execute_notebook(\n",
        "        './notebooks/training.ipynb',\n",
        "        os.path.join(OUT_DIR, f\"{params['expid']}.ipynb\"),\n",
        "        parameters = params,\n",
        "        nest_asyncio=True\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOR7N6QUw1gM",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uih93Xrlw1Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer learning experiment - Unfreeze until a given layer\n",
        "time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "print(time_expid)\n",
        "\n",
        "for eps in [3, 4, 7]:\n",
        "  for unfreeze_to_layer in [5]:\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=f'full_stability_eps={eps}_seed=1_2020-06-07---11:18:40',\n",
        "                            train_file_name=f'3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                            step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                            unfreeze_to_layer=unfreeze_to_layer, use_dropout_head=False,\n",
        "                            lr=1e-5, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                            EPOCHS=50, BATCH_SIZE=16,\n",
        "                            ADV_TRAIN=False,\n",
        "                            expid=f'transfer_learning_unfreezeto={unfreeze_to_layer}_eps={eps}_{time_expid}',\n",
        "                            seed=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ1846QvsMtU",
        "colab_type": "text"
      },
      "source": [
        "## Finding the right learning rate for the Dropout models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAyi4mqrpu1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout HEAD\n",
        "for lr in [1e-3, 3e-4, 1e-4, 3e-5]:\n",
        "  for dropout in [0]:\n",
        "    time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "    print(time_expid)\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=None,\n",
        "                          train_file_name=f'3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                          step_lr=15, arch='resnet18', do_eval_model=False,\n",
        "                          use_dropout_head=True, dropout_perc=dropout,\n",
        "                          lr=lr, custom_schedule=None, lr_patience=5, es_patience=10,\n",
        "                          EPOCHS=15, BATCH_SIZE=32,\n",
        "                          ADV_TRAIN=False,\n",
        "                          expid = f\"head_dropout_{dropout}_lr={lr}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFFZBseO7CgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout BODY\n",
        "# Fine-tuning for varying Nevi size\n",
        "\n",
        "for lr in [3e-4, 1e-4, 3e-5, 1e-5]:\n",
        "  for dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "    time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "    print(time_expid)\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=f\"head_dropout_0_lr=0.001\",\n",
        "                            train_file_name=f'3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                            step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                            use_dropout_head=True, dropout_perc=dropout,\n",
        "                            lr=lr, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                            EPOCHS=50, BATCH_SIZE=16,\n",
        "                            ADV_TRAIN=False,\n",
        "                            expid=f'full_dropout_{dropout}_adv={0}_lr={lr}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMjOK8uHeAre",
        "colab_type": "text"
      },
      "source": [
        "## Stability Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHDwfBuneAbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "print(time_expid)\n",
        "\n",
        "for seed in [1, 2, 3, 4, 5]:\n",
        "  # HEAD\n",
        "  cross_validation_train(time_expid, val_fold=0, base_model_expid=None,\n",
        "                          train_file_name='3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                          step_lr=15, arch='resnet18', do_eval_model=False,\n",
        "                          use_dropout_head=False, dropout_perc=0,\n",
        "                          lr=1e-3, custom_schedule=None, lr_patience=5, es_patience=10,\n",
        "                          EPOCHS=10, BATCH_SIZE=32,\n",
        "                          ADV_TRAIN=False,\n",
        "                          expid = f\"head_stability_seed={seed}_{time_expid}\", seed=seed)\n",
        "  \n",
        "  # FINE-TUNE\n",
        "  cross_validation_train(time_expid, val_fold=0, base_model_expid=f\"head_stability_seed={seed}_{time_expid}\",\n",
        "                          train_file_name='3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                          step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                          lr=3e-4, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                          EPOCHS=50, BATCH_SIZE=16,\n",
        "                          ADV_TRAIN=False,\n",
        "                          expid=f'full_stability_seed={seed}_{time_expid}', seed=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDsp4PaRaCg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_expid = '2020-06-07---11:18:40'\n",
        "# ADV_TRAIN\n",
        "for EPS in [7]:\n",
        "  for seed in [1, 2, 3, 4, 5]:\n",
        "    # FINE-TUNE\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=f\"head_stability_seed={seed}_{time_expid}\",\n",
        "                            train_file_name='3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                            step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                            lr=3e-4, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                            EPOCHS=50, BATCH_SIZE=16,\n",
        "                            ADV_TRAIN=True, EPS=EPS,\n",
        "                            expid=f'full_stability_eps={EPS}_seed={seed}_{time_expid}', seed=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-6FoiFYrTwo",
        "colab_type": "text"
      },
      "source": [
        "## Train Head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZSwQVe1khRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train head for Varying Training size ration\n",
        "for nevi_cnt in [50, 100, 200, 400, 800, 1600, 3200]:\n",
        "  time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "  print(time_expid)\n",
        "  cross_validation_train(time_expid, val_fold=0, base_model_expid=None,\n",
        "                        train_file_name=f'varying_training_ratio/3cls_balanced_{nevi_cnt}nevi_train_val.csv', test_file_name=test_file_name,\n",
        "                        step_lr=15, arch='resnet18', do_eval_model=False,\n",
        "                        use_dropout_head=False, dropout_perc=0,\n",
        "                        lr=1e-3, custom_schedule=None, lr_patience=5, es_patience=10,\n",
        "                        EPOCHS=10, BATCH_SIZE=32,\n",
        "                        ADV_TRAIN=False,\n",
        "                        expid = f\"head_nevi_{nevi_cnt}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o93bbyVm_1bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout\n",
        "for dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
        "  time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "  print(time_expid)\n",
        "  cross_validation_train(time_expid, val_fold=0, base_model_expid=None,\n",
        "                        train_file_name=f'3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                        step_lr=15, arch='resnet18', do_eval_model=False,\n",
        "                        use_dropout_head=True, dropout_perc=dropout,\n",
        "                        lr=1e-3, custom_schedule=None, lr_patience=5, es_patience=10,\n",
        "                        EPOCHS=10, BATCH_SIZE=32,\n",
        "                        ADV_TRAIN=False,\n",
        "                        expid = f\"head_dropout_{dropout}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKBAavKgeTGL",
        "colab_type": "text"
      },
      "source": [
        "## Training only one fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-sioRskNNwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine-tuning for varying Nevi size\n",
        "for EPS in [3, 4, 5]:\n",
        "  adv_train = EPS != 0\n",
        "  print(adv_train)\n",
        "\n",
        "  for nevi_cnt in [50, 100, 200, 400, 800, 1600, 3200]:\n",
        "    time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "    print(time_expid)\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=f\"head_nevi_{nevi_cnt}\",\n",
        "                           train_file_name=f'varying_training_ratio/3cls_balanced_{nevi_cnt}nevi_train_val.csv', test_file_name=test_file_name,\n",
        "                           step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                           lr=3e-4, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                           EPOCHS=50, BATCH_SIZE=16,\n",
        "                           ADV_TRAIN=adv_train, EPS=EPS,\n",
        "                           expid=f'full_nevi_{nevi_cnt}_adv={EPS}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zu_fuWeAYtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fine-tuning for varying Nevi size\n",
        "for EPS in [3, 4, 5]:\n",
        "  adv_train = EPS != 0\n",
        "  print(adv_train)\n",
        "\n",
        "  for dropout in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]:\n",
        "    time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "    print(time_expid)\n",
        "    cross_validation_train(time_expid, val_fold=0, base_model_expid=f\"head_dropout_{dropout}\",\n",
        "                           train_file_name=f'3cls_balanced_2400_train_val.csv', test_file_name=test_file_name,\n",
        "                           step_lr=None, arch='resnet18', do_eval_model=True,\n",
        "                           use_dropout_head=True, dropout_perc=dropout,\n",
        "                           lr=3e-4, custom_schedule='plateau', lr_patience=5, es_patience=10,\n",
        "                           EPOCHS=50, BATCH_SIZE=16,\n",
        "                           ADV_TRAIN=adv_train, EPS=EPS,\n",
        "                           expid=f'full_dropout_{dropout}_adv={EPS}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdjoOuWxQ9eG",
        "colab_type": "text"
      },
      "source": [
        "## Full-body cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxiB1FHBKywL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lr in [1e-4, 1e-3]:\n",
        "  for batch_size in [16]:\n",
        "    time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "    print(time_expid)\n",
        "    for val_fold, base_model_expid in zip([1, 2, 3, 4, 5], ['cv=1_full_std_lr=0.001_2400_2020-05-24---05:38:16', \n",
        "                                                             'cv=2_full_std_lr=0.001_2400_2020-05-24---05:38:16',\n",
        "                                                             'cv=3_full_std_lr=0.001_2400_2020-05-24---05:38:16',\n",
        "                                                             'cv=4_full_std_lr=0.001_2400_2020-05-24---05:38:16',\n",
        "                                                             'cv=5_full_std_lr=0.001_2400_2020-05-24---05:38:16']):\n",
        "\n",
        "        cross_validation_train(time_expid, val_fold=val_fold, base_model_expid=base_model_expid, file_name=file_name,\n",
        "                              lr=lr, BATCH_SIZE=batch_size,\n",
        "                              step_lr=None, EPOCHS=30, arch='resnet50',\n",
        "                              ADV_TRAIN=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pBrOXJ4KCGc",
        "colab_type": "text"
      },
      "source": [
        "# Train on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmXo6CP2Kt4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_expid = datetime.now().strftime('%Y-%m-%d---%H:%M:%S')\n",
        "print(time_expid)\n",
        "\n",
        "for EPS in [5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9]:\n",
        "  cross_validation_train(time_expid, val_fold=0, base_model_expid='cv=1_full_std_lr=0.001_2400_2020-05-24---05:38:16', file_name=file_name,\n",
        "                          lr=3e-4, BATCH_SIZE=32,\n",
        "                          step_lr=None, EPOCHS=30, arch='resnet50',\n",
        "                          ADV_TRAIN=True, EPS=EPS, constraint='2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_ZFpjwRtUvf",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPciJdqUjb6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPS = 3\n",
        "attack_kwargs = {\n",
        "    'constraint': '2',\n",
        "    'eps': EPS,\n",
        "    'attack_lr': 2.5 * EPS / 30,\n",
        "    'attack_steps': 30,\n",
        "    'random_start': True\n",
        "}\n",
        "adv_eval_args = Parameters({**attack_kwargs, **{'adv_eval': False}})\n",
        "adv_eval_args = defaults.check_and_fill_args(adv_eval_args, defaults.PGD_ARGS, CIFAR)\n",
        "adv_eval_args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5y2dIIfh_4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = HAM10000_3cls(\"/content/data\", file_name=\"3cls_balanced_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxegROhKlUCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----- TEST loader\n",
        "test_dataset = HAM10000_dataset_3cls_balanced(dataset.data_path, \"3cls_balanced_test.csv\", transform=dataset.transform_test, test=True) \n",
        "loader = DataLoader(test_dataset, batch_size=16, num_workers=16, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFkN1gKEvJxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fix_random_seed(42)\n",
        "\n",
        "model, _ = model_utils.make_and_restore_model(\n",
        "    arch='resnet50',\n",
        "    dataset=dataset,\n",
        "    resume_path=os.path.join(LOG_DIR, 'cv=0_full_adv_eps=3_lr=0.0003_2400_2020-05-13---08:57:50', 'checkpoint.pt.latest'),\n",
        "    device='cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys8hQr7muImj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.eval_model(adv_eval_args, model, loader, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyj0pNM4XOvi",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Cross_validation\n",
        "Get all folds from cross-validation and compute mean and std of the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrgpirg0XQWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_log_cross_validation(logs_dir, exp_id):\n",
        "  train_accs, val_accs = [], []\n",
        "  for fold in [1, 2, 3, 4, 5]:\n",
        "    log = cox.store.Store(logs_dir, f\"cv={fold}_{exp_id}\")\n",
        "    last_row = log.tables['logs'].df.iloc[-1]\n",
        "    log.close()\n",
        "\n",
        "    train_accs.append(last_row.train_prec1)\n",
        "    val_accs.append(last_row.nat_prec1)\n",
        "\n",
        "  print(\"Train:  %.2f +- %.2f\" % (np.mean(train_accs), np.std(train_accs)))\n",
        "  print(\"Valid:  %.2f +- %.2f\" % (np.mean(val_accs), np.std(val_accs)))\n",
        "\n",
        "read_log_cross_validation(LOG_DIR, 'full_std_lr=0.001_2400_2020-05-24---17:53:45')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}